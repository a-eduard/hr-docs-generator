import streamlit as st
import pandas as pd
import os
import io
import zipfile
import re
import pdfplumber
from docxtpl import DocxTemplate, RichText, InlineImage
from docx.shared import Mm
from num2words import num2words
from datetime import date
import pymorphy3
from PIL import Image, ImageOps

# --- 1. –ù–ê–°–¢–†–û–ô–ö–ò ---
st.set_page_config(page_title="Smart HR Architect", layout="wide", page_icon="üèóÔ∏è")

st.markdown("""
<style>
    [data-testid="stFileUploaderDropzone"] div div::before {content:"";}
    [data-testid="stFileUploaderDropzone"] div div span {display:none;}
    [data-testid="stFileUploaderDropzone"] {min-height: 80px; padding: 10px;}
</style>
""", unsafe_allow_html=True)

# --- 2. –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–ï –ú–û–î–£–õ–ï–ô ---
try:
    morph = pymorphy3.MorphAnalyzer()
except:
    pass

try:
    from ai_utils import generate_ai_duties, extract_data_from_egrul
except ImportError:
    def generate_ai_duties(p): return ""
    def extract_data_from_egrul(t): return None

# --- 3. STATE ---
keys = ["c_name", "c_short_name", "c_inn", "c_kpp", "c_ogrn", "c_address", "c_boss", "c_boss_pos", "c_opf"]
for k in keys:
    if k not in st.session_state:
        st.session_state[k] = ""

# --- 4. –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---

def clean_val(val):
    if pd.isna(val): return None
    s = str(val).strip()
    if s == "" or s.lower() == "nan": return None
    return s

def build_passport_string(row):
    row_lower = {str(k).lower().strip(): v for k, v in row.items()}
    passport_num = ""
    for key in row_lower:
        if any(x in key for x in ["–ø–∞—Å–ø–æ—Ä—Ç", "—Å–µ—Ä–∏—è", "–Ω–æ–º–µ—Ä", "–¥–æ–∫—É–º–µ–Ω—Ç"]):
            val = clean_val(row_lower[key])
            if val:
                if val.isdigit() and len(val) == 10:
                    val = f"{val[:4]} {val[4:]}"
                passport_num = val
                break
    
    issued_by = ""
    for key in row_lower:
        if any(x in key for x in ["–∫–µ–º –≤—ã–¥–∞–Ω", "–≤—ã–¥–∞–Ω", "–∫–µ–º"]):
            if "–¥–∞—Ç–∞" in key or "–∫–æ–≥–¥–∞" in key: continue
            val = clean_val(row_lower[key])
            if val: issued_by = val; break
    
    date_issued = ""
    for key in row_lower:
        if any(x in key for x in ["–¥–∞—Ç–∞", "–∫–æ–≥–¥–∞", "—á–∏—Å–ª–æ"]):
            val = clean_val(row_lower[key])
            if val:
                try: 
                    date_issued = pd.to_datetime(val, dayfirst=True).strftime("%d.%m.%Y")
                except: date_issued = val 
                break

    parts = []
    if passport_num: parts.append(f"–ü–∞—Å–ø–æ—Ä—Ç: {passport_num}")
    else: parts.append("–ü–∞—Å–ø–æ—Ä—Ç: __________________")
    if issued_by: parts.append(f"–≤—ã–¥–∞–Ω {issued_by}")
    if date_issued: parts.append(f"–¥–∞—Ç–∞ –≤—ã–¥–∞—á–∏ {date_issued}")
    return ", ".join(parts)

def clean_case(text):
    if not text: return ""
    text = str(text)
    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –≤–µ—Å—å –í–ï–†–•–ù–ò–ú –†–ï–ì–ò–°–¢–†–û–ú (–∫–∞–∫ –≤ –ï–ì–†–Æ–õ —á–∞—Å—Ç–æ –±—ã–≤–∞–µ—Ç), –¥–µ–ª–∞–µ–º –ø–µ—Ä–≤—É—é –∑–∞–≥–ª–∞–≤–Ω–æ–π
    # –ù–æ –µ—Å–ª–∏ —Ç–∞–º —Å–º–µ—à–∞–Ω–Ω—ã–π —Ä–µ–≥–∏—Å—Ç—Ä (–û–û–û "–†–æ–º–∞—à–∫–∞"), –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
    upper_chars = sum(1 for c in text if c.isupper())
    if len(text) > 4 and (upper_chars / len(text)) > 0.8:
        return text.capitalize() # –ë–´–õ–û: text.capitalize(). –¢–ï–ü–ï–†–¨: –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —É–º–Ω–µ–µ, –Ω–æ –ø–æ–∫–∞ –æ—Å—Ç–∞–≤–∏–º
    return text

def try_read_csv(file_source, encoding, sep):
    try:
        if hasattr(file_source, 'seek'): file_source.seek(0)
        df = pd.read_csv(file_source, sep=sep, encoding=encoding, on_bad_lines='skip')
        if len(df.columns) > 1: return df
    except: pass
    return None

def load_data_file(key_label, local_filename):
    file_source = None
    local_path_xlsx = f"data/{local_filename}.xlsx"
    local_path_csv = f"data/{local_filename}.csv"
    
    uploaded = st.sidebar.file_uploader(f"–ó–∞–≥—Ä—É–∑–∏—Ç—å {key_label}", type=["csv", "xlsx"], key=local_filename)
    if uploaded: file_source = uploaded
    elif os.path.exists(local_path_xlsx): file_source = local_path_xlsx
    elif os.path.exists(local_path_csv): file_source = local_path_csv
            
    if not file_source: return None

    try:
        df = None
        if hasattr(file_source, 'name') and file_source.name.endswith('.xlsx'):
             df = pd.read_excel(file_source)
        elif isinstance(file_source, str) and file_source.endswith('.xlsx'):
             df = pd.read_excel(file_source)
        else:
            df = try_read_csv(file_source, 'cp1251', ';')
            if df is None: df = try_read_csv(file_source, 'utf-8-sig', ',')
            if df is None: df = try_read_csv(file_source, 'cp1251', ',')

        if df is not None:
            df.columns = df.columns.str.strip()
            if '–§–ò–û' in df.columns:
                if '–î–æ–ª–∂–Ω–æ—Å—Ç—å' in df.columns:
                    df['search_key'] = df['–§–ò–û'] + " ‚Äî " + df['–î–æ–ª–∂–Ω–æ—Å—Ç—å']
                else:
                    df['search_key'] = df['–§–ò–û']
            return df
        return None
    except Exception as e:
        st.sidebar.error(f"–û—à–∏–±–∫–∞ {key_label}: {e}")
        return None

def parse_egrul_pdf_ai(pdf_file):
    full_text = ""
    try:
        with pdfplumber.open(pdf_file) as pdf:
            for page in pdf.pages:
                extracted = page.extract_text()
                if extracted: full_text += extracted + "\n"
    except Exception as e:
        return None, f"–û—à–∏–±–∫–∞ PDF: {e}"
    if not full_text: return None, "PDF –ø—É—Å—Ç–æ–π."
    data = extract_data_from_egrul(full_text)
    if not data: return None, "AI –Ω–µ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã–µ."
    return data, None

def make_times_new_roman(text):
    if not text: return ""
    rt = RichText()
    rt.add(str(text), font='Times New Roman', size=24)
    return rt

# --- –§–£–ù–ö–¶–ò–ò –û–ë–†–ê–ë–û–¢–ö–ò –¢–ï–ö–°–¢–ê ---

def get_inflected(text: str, case_tag: str) -> str:
    if not text or 'morph' not in globals(): return text
    res = []
    for w in text.split():
        try:
            is_capitalized = w[0].isupper()
            p = morph.parse(w)[0]
            inflected = p.inflect({case_tag})
            
            if inflected:
                word = inflected.word
                if is_capitalized: word = word.capitalize()
                res.append(word)
            else:
                res.append(w)
        except:
            res.append(w)
    
    final_str = " ".join(res)
    if final_str:
        return final_str[0].upper() + final_str[1:]
    return ""

def get_initials(full_name: str) -> str:
    if not full_name: return ""
    p = full_name.split()
    if len(p) >= 3:
        return f"{p[0].capitalize()} {p[1][0].upper()}.{p[2][0].upper()}."
    return full_name

def get_gender_word(fio: str, word_masc: str, word_fem: str) -> str:
    if not fio: return word_masc
    parts = fio.split()
    if len(parts) >= 3:
        patr = parts[2].lower()
        if patr.endswith("–≤–Ω–∞") or patr.endswith("—á–Ω–∞") or patr.endswith("—à–Ω–∞"):
            return word_fem
        if patr.endswith("–≤–∏—á"):
            return word_masc
    if len(parts) >= 2 and 'morph' in globals():
        try:
            parsed = morph.parse(parts[1])[0] 
            if 'femn' in parsed.tag: return word_fem
        except: pass
    return word_masc

def increment_doc_number(base_num: str, step: int) -> str:
    if step == 0: return base_num
    match = re.search(r'\d+', base_num)
    if match:
        number_str = match.group()
        new_number = int(number_str) + step
        return base_num.replace(number_str, str(new_number), 1)
    return f"{base_num}-{step + 1}"

# --- –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø ---

def trim_whitespace(img):
    try:
        if img.mode != "RGBA":
            img = img.convert("RGBA")
        alpha = img.split()[-1]
        bbox = alpha.getbbox()
        if bbox: return img.crop(bbox)
        return img
    except: return img

def create_overlay_image(sign_path, stamp_path):
    try:
        if not sign_path or not os.path.exists(sign_path): return None
        sign_img = Image.open(sign_path).convert("RGBA")
        sign_img = trim_whitespace(sign_img)
        
        if stamp_path and os.path.exists(stamp_path):
            stamp_img = Image.open(stamp_path).convert("RGBA")
            stamp_img = trim_whitespace(stamp_img)
            target_h = int(sign_img.height * 1.3)
            if target_h < 150: target_h = 150 
            ratio = target_h / stamp_img.height
            target_w = int(stamp_img.width * ratio)
            stamp_img = stamp_img.resize((target_w, target_h), Image.Resampling.LANCZOS)
            
            shift_x = int(sign_img.width * 0.6) 
            canvas_w = max(sign_img.width, shift_x + stamp_img.width) + 10
            canvas_h = max(sign_img.height, stamp_img.height) + 10
            new_img = Image.new('RGBA', (canvas_w, canvas_h), (255, 255, 255, 0))
            
            y_sign = (canvas_h - sign_img.height) // 2
            new_img.paste(sign_img, (0, y_sign), sign_img)
            y_stamp = (canvas_h - stamp_img.height) // 2
            new_img.paste(stamp_img, (shift_x, y_stamp), stamp_img)
            
            temp_path = "data/signatures/temp_combo.png"
            new_img.save(temp_path, format="PNG")
            return temp_path
            
        temp_path = "data/signatures/temp_sign_trimmed.png"
        sign_img.save(temp_path, format="PNG")
        return temp_path
    except: return sign_path

def get_image_object(doc, filename_or_path, width_mm, do_trim=True):
    if not filename_or_path: return "[–ü–£–°–¢–û–ï –ò–ú–Ø]"
    
    path = filename_or_path
    if not os.path.exists(path):
        base = os.path.join("data", "signatures", filename_or_path)
        if os.path.exists(base): path = base
        elif os.path.exists(base + ".png"): path = base + ".png"
        elif os.path.exists(base + ".jpg"): path = base + ".jpg"
        elif os.path.exists(base + ".jpeg"): path = base + ".jpeg"
        else:
            return f"[–ù–ï–¢ –§–ê–ô–õ–ê: {filename_or_path}]"

    final_path = path
    if do_trim and "temp" not in path: 
        try:
            img = Image.open(path)
            img = trim_whitespace(img)
            trimmed_name = f"trimmed_{os.path.basename(path)}"
            final_path = os.path.join("data", "signatures", trimmed_name)
            img.save(final_path, format="PNG")
        except Exception as e:
            return f"[–û–®–ò–ë–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò: {e}]"

    try: 
        return InlineImage(doc, final_path, width=Mm(width_mm))
    except Exception as e:
        return f"[–û–®–ò–ë–ö–ê –í–°–¢–ê–í–ö–ò: {e}]"

# --- 5. –ò–ù–¢–ï–†–§–ï–ô–° ---

st.sidebar.header("üìÇ –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
df_emp = load_data_file("–°–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤", "employees")
df_resp = load_data_file("–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö", "responsible")

st.sidebar.divider()
st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
use_ai_duties = st.sidebar.toggle("ü§ñ –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏", value=True)
selected_style = st.sidebar.selectbox("–°—Ç–∏–ª—å —à–∞–±–ª–æ–Ω–æ–≤", ["style1", "style2", "style3", "style4", "style5", "style6"], index=0)

with st.sidebar.expander("‚úíÔ∏è –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–¥–ø–∏—Å–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"):
    uploaded_sigs = st.file_uploader("–§–∞–π–ª—ã (–Ω–∞–∑–≤–∞–Ω–∏–µ = –§–ò–û)", type=["png", "jpg"], accept_multiple_files=True)
    if uploaded_sigs:
        if not os.path.exists("data/signatures"): os.makedirs("data/signatures")
        for f in uploaded_sigs:
            with open(os.path.join("data/signatures", f.name), "wb") as dest:
                dest.write(f.getbuffer())
        st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(uploaded_sigs)} –ø–æ–¥–ø–∏—Å–µ–π")

st.title("üèóÔ∏è –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä PRO (v8.0)")
st.markdown("---")

if df_emp is None:
    st.info("üëà –ó–∞–≥—Ä—É–∑–∏—Ç–µ –±–∞–∑—É –°–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤.")
    st.stop()

col_left, col_right = st.columns([1, 1.3])

with col_left:
    st.subheader("1. –í—ã–±–æ—Ä –ø–µ—Ä—Å–æ–Ω–∞–ª–∞")
    options = df_emp['search_key'].unique()
    selected_emp_keys = st.multiselect("–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏:", options)
    
    st.markdown("")
    st.write("üßë‚Äçüíº **–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ –ª–∏—Ü–æ:**")
    selected_resp_key = "--- –ù–µ —É–∫–∞–∑—ã–≤–∞—Ç—å ---"
    
    if df_resp is not None:
        resp_options = ["--- –ù–µ —É–∫–∞–∑—ã–≤–∞—Ç—å ---"] + list(df_resp['search_key'].unique())
        selected_resp_key = st.selectbox("–ö—Ç–æ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö:", resp_options)

    st.markdown("---")
    st.subheader("2. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã")
    c1, c2 = st.columns(2)
    with c1:
        start_doc_num = st.text_input("–ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞", "12-–ö")
        salary = st.number_input("–û–∫–ª–∞–¥", value=120000, step=5000)
    with c2:
        doc_date = st.date_input("–î–∞—Ç–∞", date.today())
        city = st.text_input("–ì–æ—Ä–æ–¥", "–ú–æ—Å–∫–≤–∞")

with col_right:
    st.subheader("3. –î–∞–Ω–Ω—ã–µ –†–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è")
    uploaded_pdf = st.file_uploader("1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –ï–ì–†–Æ–õ (PDF)", type=["pdf"])
    
    if uploaded_pdf:
        if st.button("üöÄ –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å —á–µ—Ä–µ–∑ YandexGPT", type="secondary"):
            with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é..."):
                extracted, err = parse_egrul_pdf_ai(uploaded_pdf)
                if err: st.error(err)
                elif extracted:
                    if "inn" in extracted: st.session_state.c_inn = extracted["inn"]
                    if "kpp" in extracted: st.session_state.c_kpp = extracted["kpp"]
                    if "ogrn" in extracted: st.session_state.c_ogrn = extracted["ogrn"]
                    
                    # –û–ë–ù–û–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ä–µ–≥–∏—Å—Ç—Ä –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è (–±–µ–∑ clean_case), 
                    # –∏–ª–∏ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —á–∏—Å—Ç–∏–º, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                    name_extracted = extracted.get("name", "")
                    # –ï—Å–ª–∏ –≤—Å–µ –∫–∞–ø—Å–æ–º - –¥–µ–ª–∞–µ–º –∫—Ä–∞—Å–∏–≤–æ, –µ—Å–ª–∏ –Ω–µ—Ç - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                    if name_extracted.isupper():
                        st.session_state.c_name = clean_case(name_extracted)
                    else:
                        st.session_state.c_name = name_extracted
                        
                    if "short_name" in extracted: st.session_state.c_short_name = extracted["short_name"]
                    if "address" in extracted: st.session_state.c_address = clean_case(extracted["address"])
                    if "boss_name" in extracted: st.session_state.c_boss = clean_case(extracted["boss_name"])
                    if "boss_pos" in extracted: st.session_state.c_boss_pos = clean_case(extracted["boss_pos"])
                    if "opf" in extracted: st.session_state.c_opf = clean_case(extracted["opf"])
                    st.success(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {extracted.get('name')}")
                    st.rerun()

    st.markdown("##### üñÉ –ü–µ—á–∞—Ç—å –∏ –ü–æ–¥–ø–∏—Å—å –î–∏—Ä–µ–∫—Ç–æ—Ä–∞:")
    c_stamp, c_dir = st.columns(2)
    stamp_path_temp = None
    director_path_temp = None
    if not os.path.exists("data/signatures"): os.makedirs("data/signatures")

    with c_stamp:
        up_stamp = st.file_uploader("–ü–µ—á–∞—Ç—å (PNG)", type=["png"], key="u_stamp")
        if up_stamp:
            stamp_path_temp = "data/signatures/temp_stamp_session.png"
            with open(stamp_path_temp, "wb") as f: f.write(up_stamp.getbuffer())

    with c_dir:
        up_dir = st.file_uploader("–ü–æ–¥–ø–∏—Å—å –î–∏—Ä–µ–∫—Ç–æ—Ä–∞ (PNG)", type=["png"], key="u_dir")
        if up_dir:
            director_path_temp = "data/signatures/temp_director_session.png"
            with open(director_path_temp, "wb") as f: f.write(up_dir.getbuffer())

    st.markdown("##### üìù –†–µ–∫–≤–∏–∑–∏—Ç—ã:")
    st.text_input("–û—Ä–≥.-–ø—Ä–∞–≤–æ–≤–∞—è —Ñ–æ—Ä–º–∞", key="c_opf")
    st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ (–±–µ–∑ –û–ü–§)", key="c_name")
    st.text_input("–°–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ", key="c_short_name")
    c_i, c_k, c_o = st.columns([1, 1, 1])
    with c_i: st.text_input("–ò–ù–ù", key="c_inn")
    with c_k: st.text_input("–ö–ü–ü", key="c_kpp")
    with c_o: st.text_input("–û–ì–†–ù", key="c_ogrn")
    st.text_area("–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å", key="c_address", height=68)
    c_b1, c_b2 = st.columns(2)
    with c_b1: st.text_input("–§–ò–û –î–∏—Ä–µ–∫—Ç–æ—Ä–∞", key="c_boss")
    with c_b2: st.text_input("–î–æ–ª–∂–Ω–æ—Å—Ç—å", key="c_boss_pos")

st.markdown("---")
if st.button("üöÄ –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã", type="primary", use_container_width=True):
    
    if not selected_emp_keys:
        st.error("‚ùå –í—ã–±–µ—Ä–∏—Ç–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤!")
        st.stop()

    # --- –ü–û–î–ì–û–¢–û–í–ö–ê –û–ë–©–ò–• –î–ê–ù–ù–´–• ---
    tasks = []
    for key in selected_emp_keys:
        row = df_emp[df_emp['search_key'] == key].iloc[0]
        tasks.append({"data": row, "role": "emp"})
        
    opf = st.session_state.c_opf.strip()
    name = st.session_state.c_name.strip()
    
    # === –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–†–Ø–ú–ê–Ø –°–ö–õ–ï–ô–ö–ê ===
    # –ë–æ–ª—å—à–µ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–∏–∫–∞–∫–∏—Ö –∫–∞–≤—ã—á–µ–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.
    # –ß—Ç–æ –Ω–∞–ø–∏—Å–∞–Ω–æ –≤ –ø–æ–ª—è—Ö "–û–ü–§" –∏ "–ù–∞–∑–≤–∞–Ω–∏–µ" ‚Äî —Ç–æ –∏ –±—É–¥–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ.
    full_company_name = f"{opf} {name}".strip()
    # ===================================
             
    b_name = st.session_state.c_boss
    b_pos = st.session_state.c_boss_pos
    short_name_val = st.session_state.c_short_name if st.session_state.c_short_name else full_company_name
    
    resp_name_str = ""
    resp_pos_str = ""
    resp_doc_str = ""
    if df_resp is not None and selected_resp_key != "--- –ù–µ —É–∫–∞–∑—ã–≤–∞—Ç—å ---":
        r_row = df_resp[df_resp['search_key'] == selected_resp_key].iloc[0]
        resp_name_str = r_row.get('–§–ò–û', '')
        resp_pos_str = r_row.get('–î–æ–ª–∂–Ω–æ—Å—Ç—å', '')
        for k_resp, v_resp in r_row.items():
            if any(x in str(k_resp).lower() for x in ["–æ—Å–Ω–æ–≤–∞–Ω–∏–µ", "–¥–æ–∫—É–º–µ–Ω—Ç", "–¥–æ–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"]):
                 resp_doc_str = str(v_resp)
                 break

    reqs_str = f"{full_company_name}\n–Æ—Ä. –∞–¥—Ä–µ—Å: {st.session_state.c_address}\n–ò–ù–ù {st.session_state.c_inn}, –ö–ü–ü {st.session_state.c_kpp}, –û–ì–†–ù {st.session_state.c_ogrn}"
    rt_reqs = make_times_new_roman(reqs_str)

    date_short = doc_date.strftime("%d.%m.%Y") + " –≥."
    months_ru = ["—è–Ω–≤–∞—Ä—è", "—Ñ–µ–≤—Ä–∞–ª—è", "–º–∞—Ä—Ç–∞", "–∞–ø—Ä–µ–ª—è", "–º–∞—è", "–∏—é–Ω—è", "–∏—é–ª—è", "–∞–≤–≥—É—Å—Ç–∞", "—Å–µ–Ω—Ç—è–±—Ä—è", "–æ–∫—Ç—è–±—Ä—è", "–Ω–æ—è–±—Ä—è", "–¥–µ–∫–∞–±—Ä—è"]
    date_full = f"¬´{doc_date.day:02d}¬ª {months_ru[doc_date.month - 1]} {doc_date.year} –≥."

    combo_path = None
    if director_path_temp:
        combo_path = create_overlay_image(director_path_temp, stamp_path_temp)
    
    zip_buf = io.BytesIO()
    files_ok = 0
    progress = st.progress(0)
    
    # 2. –î–û–ë–ê–í–õ–Ø–ï–ú –°–¢–ò–õ–¨ –í –ò–ú–ï–ù–ê –§–ê–ô–õ–û–í
    style_suffix = f"_{selected_style}"
    
    with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as zf:
        
        info_text = f"""–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {date.today()}
–ö–æ–º–ø–∞–Ω–∏—è: {full_company_name}
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Å—Ç–∏–ª—å: {selected_style}
–°–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(tasks)}
        """
        zf.writestr("00_INFO.txt", info_text)

        company_ctx = {
            "city": city, "contract_date": date_short, "date_ru": date_full,
            "company_name": full_company_name, "company_short": short_name_val,
            "company_address": st.session_state.c_address,
            "company_inn": st.session_state.c_inn, "company_kpp": st.session_state.c_kpp, "company_ogrn": st.session_state.c_ogrn,
            "head_name": b_name, "head_pos": b_pos, "head_short": get_initials(b_name),
            "head_name_gen": get_inflected(b_name, 'gent'), 
            "head_pos_gen": get_inflected(b_pos, 'gent'),
            "head_name_accs": get_inflected(b_name, 'accs'), 
            "head_pos_accs": get_inflected(b_pos, 'accs'),
            "head_pos_datv": get_inflected(b_pos, 'datv'),
            "employer_reqs": rt_reqs,
            "director_combo": get_image_object(DocxTemplate(io.BytesIO()), combo_path, 45, False) if combo_path else "",
        }

        # --- 1. –û–ü–ò–°–¨ ---
        inventory_path = "templates/inventory.docx"
        if os.path.exists(inventory_path):
            try:
                doc_inv = DocxTemplate(inventory_path)
                doc_inv.render(company_ctx)
                tmp_inv = io.BytesIO()
                doc_inv.save(tmp_inv)
                zf.writestr(f"00_–û–ø–∏—Å—å{style_suffix}.docx", tmp_inv.getvalue())
                files_ok += 1
            except Exception as e: pass

        # --- 2. –°–í–û–î–ù–´–ô –ü–†–ò–ö–ê–ó ---
        style_num = selected_style.replace("style", "") 
        order_tmpl_path = f"templates/orders/{style_num}.docx"
        
        if os.path.exists(order_tmpl_path):
            try:
                doc_ord = DocxTemplate(order_tmpl_path)
                employees_list = []
                for t in tasks:
                    emp_data = t["data"]
                    fio = emp_data['–§–ò–û']
                    pos = emp_data.get('–î–æ–ª–∂–Ω–æ—Å—Ç—å', '')
                    
                    employees_list.append({
                        "name": fio,
                        "short": get_initials(fio),
                        "pos": pos,
                        "name_gen": get_inflected(fio, 'gent'),
                        "pos_gen": get_inflected(pos, 'gent'),
                        "name_accs": get_inflected(fio, 'accs'), 
                        "pos_accs": get_inflected(pos, 'accs'),
                        "accepted": get_gender_word(fio, "–ø—Ä–∏–Ω—è—Ç", "–ø—Ä–∏–Ω—è—Ç–∞"),
                        "appointed": get_gender_word(fio, "–Ω–∞–∑–Ω–∞—á–µ–Ω", "–Ω–∞–∑–Ω–∞—á–µ–Ω–∞"),
                        "sign": get_image_object(doc_ord, fio, 20, True) 
                    })
                
                ctx_ord = company_ctx.copy()
                ctx_ord["col_employees"] = employees_list
                if combo_path: 
                    ctx_ord["director_combo"] = get_image_object(doc_ord, combo_path, 45, False)
                    ctx_ord["director_sign"] = get_image_object(doc_ord, director_path_temp, 30, True)

                doc_ord.render(ctx_ord)
                tmp_ord = io.BytesIO()
                doc_ord.save(tmp_ord)
                zf.writestr(f"00_–°–≤–æ–¥–Ω—ã–π_–ø—Ä–∏–∫–∞–∑_–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–µ{style_suffix}.docx", tmp_ord.getvalue())
                files_ok += 1
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ —Å–≤–æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∫–∞–∑–∞: {e}")

        # --- 3. –ü–†–ò–ö–ê–ó –ù–ê –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–ì–û ---
        target_resp = {}
        if df_resp is not None and selected_resp_key != "--- –ù–µ —É–∫–∞–∑—ã–≤–∞—Ç—å ---":
             r_row = df_resp[df_resp['search_key'] == selected_resp_key].iloc[0]
             target_resp = { "name": r_row['–§–ò–û'], "pos": r_row.get('–î–æ–ª–∂–Ω–æ—Å—Ç—å', ''), "is_director": False }
             filename_resp = f"–ü—Ä–∏–∫–∞–∑_–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π_{get_initials(r_row['–§–ò–û'])}"
        else:
             target_resp = { "name": b_name, "pos": b_pos, "is_director": True }
             filename_resp = f"–ü—Ä–∏–∫–∞–∑_–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π_–î–∏—Ä–µ–∫—Ç–æ—Ä"
             
        if os.path.exists(order_tmpl_path):
             try:
                doc_r = DocxTemplate(order_tmpl_path)
                person_data = {
                    "name": target_resp["name"],
                    "short": get_initials(target_resp["name"]),
                    "pos": target_resp["pos"],
                    "name_gen": get_inflected(target_resp["name"], 'gent'),
                    "pos_gen": get_inflected(target_resp["pos"], 'gent'),
                    "name_accs": get_inflected(target_resp["name"], 'accs'),
                    "pos_accs": get_inflected(target_resp["pos"], 'accs'),
                    "accepted": get_gender_word(target_resp["name"], "–ø—Ä–∏–Ω—è—Ç", "–ø—Ä–∏–Ω—è—Ç–∞"),
                    "appointed": get_gender_word(target_resp["name"], "–Ω–∞–∑–Ω–∞—á–µ–Ω", "–Ω–∞–∑–Ω–∞—á–µ–Ω–∞"),
                    "sign": get_image_object(doc_r, director_path_temp, 30, True) if target_resp["is_director"] else get_image_object(doc_r, target_resp["name"], 20, True)
                }
                ctx_r = company_ctx.copy()
                ctx_r["col_employees"] = [person_data]
                if combo_path: 
                    ctx_r["director_combo"] = get_image_object(doc_r, combo_path, 45, False)
                    ctx_r["director_sign"] = get_image_object(doc_r, director_path_temp, 30, True)
                doc_r.render(ctx_r)
                tmp_r = io.BytesIO()
                doc_r.save(tmp_r)
                zf.writestr(f"00_{filename_resp}{style_suffix}.docx", tmp_r.getvalue())
                files_ok += 1
             except Exception as e: pass

        # --- 4. –õ–ò–ß–ù–´–ï –î–û–ö–£–ú–ï–ù–¢–´ ---
        for i, task in enumerate(tasks):
            emp = task["data"]
            role = task["role"]
            progress.progress((i + 1) / len(tasks))
            
            doc_num = increment_doc_number(start_doc_num, i)
            ai_duties = ""
            if use_ai_duties and role == "emp":
                try: ai_duties = generate_ai_duties(emp['–î–æ–ª–∂–Ω–æ—Å—Ç—å'])
                except: ai_duties = "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"

            full_passport_str = build_passport_string(emp)
            pos_nom = emp.get('–î–æ–ª–∂–Ω–æ—Å—Ç—å', '')
            
            context = company_ctx.copy()
            context.update({
                "doc_number": doc_num,
                "resp_name": resp_name_str, "resp_pos": resp_pos_str, "resp_doc": resp_doc_str,
                "resp_short": get_initials(resp_name_str),
                "employee_name": emp['–§–ò–û'], "employee_short": get_initials(emp['–§–ò–û']),
                "employee_pos": pos_nom,
                "employee_pos_gen": get_inflected(pos_nom, 'gent'),
                "employee_pos_dat": get_inflected(pos_nom, 'datv'),
                "employee_pos_accs": get_inflected(pos_nom, 'accs'),
                "salary_digits": f"{salary:,}".replace(",", " "),
                "salary_words": num2words(salary, lang='ru').capitalize() + " —Ä—É–±–ª–µ–π 00 –∫–æ–ø–µ–µ–∫",
                "employee_reqs": make_times_new_roman(full_passport_str),
                "employee_passport": f"{full_passport_str}",
                "ai_duties": make_times_new_roman(ai_duties)
            })

            paths = {
                "–¢—Ä—É–¥–æ–≤–æ–π_–¥–æ–≥–æ–≤–æ—Ä": f"templates/contracts/{selected_style}.docx", 
                "–ü—Ä–∏–∫–∞–∑": "templates/order.docx",
                "–î–æ–ª–∂–Ω–æ—Å—Ç–Ω–∞—è": f"templates/instructions/{emp.get('–î–æ–ª–∂–Ω–æ—Å—Ç—å','').strip()}_{selected_style}.docx"
            }
            
            for name, path in paths.items():
                if role == "resp" and name == "–î–æ–ª–∂–Ω–æ—Å—Ç–Ω–∞—è": continue
                if os.path.exists(path):
                    try:
                        doc = DocxTemplate(path)
                        if combo_path: context["director_combo"] = get_image_object(doc, combo_path, 45, do_trim=False)
                        if director_path_temp: context["director_sign"] = get_image_object(doc, director_path_temp, 30, do_trim=True)
                        context["employee_sign"] = get_image_object(doc, emp['–§–ò–û'], 20, do_trim=True)
                        if resp_name_str: context["resp_sign"] = get_image_object(doc, resp_name_str, 20, do_trim=True)
                        
                        doc.render(context)
                        tmp = io.BytesIO()
                        doc.save(tmp)
                        safe_fio = get_initials(emp['–§–ò–û']).replace(".", "")
                        suffix = "_RESP" if role == "resp" else ""
                        zf.writestr(f"{i+1:02d}_{safe_fio}{suffix}_{name}{style_suffix}.docx", tmp.getvalue())
                        files_ok += 1
                    except Exception: pass
    progress.progress(100)
    
    if files_ok > 0:
        zip_buf.seek(0)
        st.success(f"‚úÖ –§–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {files_ok}")
        st.download_button("üíæ –°–∫–∞—á–∞—Ç—å ZIP", zip_buf, f"Docs_{date.today()}.zip", "application/zip")
    else:
        st.error("–®–∞–±–ª–æ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")